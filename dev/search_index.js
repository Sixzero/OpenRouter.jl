var documenterSearchIndex = {"docs":
[{"location":"#OpenRouter","page":"Home","title":"OpenRouter","text":"Documentation for OpenRouter.\n\n","category":"section"},{"location":"#OpenRouter.AbstractLLMStream","page":"Home","title":"OpenRouter.AbstractLLMStream","text":"AbstractLLMStream\n\nAbstract type for LLM stream callbacks.\n\nMust have fields:\n\nout: Output stream (e.g., stdout or pipe)\nschema: Request schema determining API format\nchunks: List of received AbstractStreamChunk chunks\nverbose: Whether to print verbose information\nkwargs: Custom keyword arguments\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.AbstractRequestSchema","page":"Home","title":"OpenRouter.AbstractRequestSchema","text":"Abstract base type for request schemas.\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.AbstractResponseSchema","page":"Home","title":"OpenRouter.AbstractResponseSchema","text":"Abstract base type for response schemas.\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.AbstractSchema","page":"Home","title":"OpenRouter.AbstractSchema","text":"Abstract base type for all API schemas.\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.AbstractStreamChunk","page":"Home","title":"OpenRouter.AbstractStreamChunk","text":"AbstractStreamChunk\n\nAbstract type for stream chunks.\n\nMust have fields:\n\nevent: The event name\ndata: The data chunk  \njson: The JSON object or nothing if chunk doesn't contain JSON\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.AnthropicSchema","page":"Home","title":"OpenRouter.AnthropicSchema","text":"Anthropic Claude-style request schema.\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.ChatCompletionResponseSchema","page":"Home","title":"OpenRouter.ChatCompletionResponseSchema","text":"Standard OpenAI-compatible response schema.\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.ChatCompletionSchema","page":"Home","title":"OpenRouter.ChatCompletionSchema","text":"Standard OpenAI-compatible chat completion request schema. This is the default schema used by most providers.\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.GeminiSchema","page":"Home","title":"OpenRouter.GeminiSchema","text":"Google Gemini-style request schema.\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.HttpStreamCallback","page":"Home","title":"OpenRouter.HttpStreamCallback","text":"HttpStreamCallback\n\nHTTP-based streaming callback that prints content to output stream. When streaming completes, builds response body from chunks as if it was a normal API response.\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.HttpStreamHooks","page":"Home","title":"OpenRouter.HttpStreamHooks","text":"HttpStreamHooks\n\nA stream callback that combines token counting with customizable hooks for various events.\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.ResponseSchema","page":"Home","title":"OpenRouter.ResponseSchema","text":"ResponseSchema <: AbstractRequestSchema\n\nSchema for OpenAI's Responses API (v1/responses endpoint). Used by newer models like gpt-5.1 and o-series models.\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.RunInfo","page":"Home","title":"OpenRouter.RunInfo","text":"RunInfo(; creation_time=time(), inference_start=nothing, last_message_time=nothing, stop_sequence=nothing)\n\nTracks run statistics and metadata during the streaming process.\n\nFields\n\ncreation_time: When the callback was created\ninference_start: When the model started processing\nlast_message_time: Timestamp of the last received message\nstop_sequence: The sequence that caused the generation to stop (if any). For OpenAI this can be:\nA specific stop sequence provided in the chunk's delta.stop_sequence\n\"stop\" if finish_reason is \"stop\"\nFor Anthropic this is the stop_sequence provided in the chunk.\n\nTiming Methods\n\nget_total_elapsed(info): Get total elapsed time since callback creation\nget_inference_elapsed(info): Get elapsed time for inference phase only\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.StreamChunk","page":"Home","title":"OpenRouter.StreamChunk","text":"StreamChunk\n\nA chunk of streaming data. A message is composed of multiple chunks.\n\nFields\n\nevent: The event name\ndata: The data chunk\njson: The JSON object or nothing if chunk doesn't contain JSON\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter.TokenCounts","page":"Home","title":"OpenRouter.TokenCounts","text":"TokenCounts\n\nUniversal token counting struct that standardizes token usage across all providers and schemas.\n\nFields\n\nprompt_tokens::Int: Number of input/prompt tokens (excluding cached)\ncompletion_tokens::Int: Number of output/completion tokens  \ntotal_tokens::Int: Total tokens used (should equal sum of all token types)\ninput_cache_read::Int: Number of tokens read from cache\ninput_cache_write::Int: Number of tokens written to cache  \ninternal_reasoning::Int: Number of reasoning/thinking tokens (e.g., Gemini thoughts, Anthropic thinking)\ninput_audio_cache::Int: Number of audio tokens cached\n\nNote: Different providers use different naming conventions:\n\nOpenAI: prompttokens, completiontokens, cachedtokens (in prompttokens_details)\nAnthropic: inputtokens, outputtokens, cachecreationinputtokens, cachereadinputtokens\nGemini: promptTokenCount, candidatesTokenCount, thoughtsTokenCount\n\n\n\n\n\n","category":"type"},{"location":"#OpenRouter._aigen_core-Tuple{Any, OpenRouter.ProviderInfo, AbstractString, ProviderEndpoint}","page":"Home","title":"OpenRouter._aigen_core","text":"Core function that handles both streaming and non-streaming API calls.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter._list_models_unfiltered","page":"Home","title":"OpenRouter._list_models_unfiltered","text":"_list_models_unfiltered(api_key::String = get(ENV, \"OPENROUTER_API_KEY\", \"\"))::Vector{OpenRouterModel}\n\nInternal helper: return all models without any provider-based filtering, using the raw API. Used by update_db to avoid recursive use of the cache.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.add_custom_model","page":"Home","title":"OpenRouter.add_custom_model","text":"add_custom_model(id::String, name::String, description::String=\"Custom model\",\n                context_length::Union{Int,Nothing}=nothing,\n                pricing::Union{Pricing,Nothing}=nothing,\n                architecture::Union{Architecture,Nothing}=nothing)\n\nAdd a custom model to the local cache.\n\nExample\n\nadd_custom_model(\"echo/100tps\", \"Echo 100 TPS\", \"Fast echo model for testing\", 8192)\nadd_custom_model(\"local/llama3\", \"Local Llama 3\", \"Self-hosted Llama 3\", 4096)\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.add_model","page":"Home","title":"OpenRouter.add_model","text":"add_model(id::String, name::String, description::String=\"Custom model\",\n         context_length::Union{Int,Nothing}=nothing,\n         pricing::Union{Pricing,Nothing}=nothing,\n         architecture::Union{Architecture,Nothing}=nothing)\n\nAdd a model to the local cache.\n\nExample\n\nadd_model(\"echo/100tps\", \"Echo 100 TPS\", \"Fast echo model for testing\", 8192)\nadd_model(\"ollama/llama3\", \"Local Llama 3\", \"Self-hosted Llama 3\", 4096)\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.add_provider","page":"Home","title":"OpenRouter.add_provider","text":"add_provider(name::String, base_url::String, auth_header_format::String=\"Bearer\", \n            api_key_env_var::Union{String,Nothing}=nothing, \n            default_headers::Dict{String,String}=Dict{String,String}(),\n            model_name_transform::Union{Function,Nothing}=nothing,\n            schema::AbstractRequestSchema=ChatCompletionSchema(),\n            notes::String=\"Custom provider\")\n\nAdd a provider to the registry.\n\nExample\n\nadd_provider(\"echo\", \"http://localhost:8080/v1\", \"Bearer\", \"ECHO_API_KEY\")\nadd_provider(\"ollama\", \"http://localhost:11434/v1\", \"Bearer\")\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.aigen-Tuple{Any, String}","page":"Home","title":"OpenRouter.aigen","text":"aigen(prompt, provider_model::String; \n      schema::Union{AbstractRequestSchema, Nothing} = nothing,\n      api_key::Union{String, Nothing} = nothing,\n      sys_msg = nothing,\n      streamcallback::Union{Nothing, AbstractLLMStream} = nothing,\n      kwargs...)\n\nGenerate text using a specific provider and model.\n\nArguments\n\nprompt: The input prompt (String or Vector of message dicts)\nprovider_model::String: Format \"Provider:model/slug\" (e.g., \"Together:moonshotai/kimi-k2-thinking\")\n\nKeyword Arguments\n\nschema::Union{AbstractRequestSchema, Nothing}: Request schema to use (auto-detected if not provided)\napi_key::Union{String, Nothing}: Provider-specific API key (auto-detected from env if not provided)\nsys_msg: System message/instruction\nstreamcallback::Union{Nothing, AbstractLLMStream}: Stream callback for real-time processing\nkwargs...: Additional API parameters\n\nReturns\n\nAIMessage: Generated response with metadata (cost, tokens, etc.)\n\nExample\n\nresponse = aigen(\"Write a haiku about Julia programming\", \"Together:moonshotai/kimi-k2-thinking\")\nprintln(response.content)\nprintln(\"Cost: $(response.cost)\")\n\n# Using system message\nresponse = aigen(\"Hello\", \"Anthropic:claude-3-sonnet\"; sys_msg=\"You are a helpful assistant\")\n\n# Using streaming\nusing OpenRouter\ncallback = HttpStreamCallback(; out=stdout)\nresponse = aigen(\"Count to 10\", \"anthropic:anthropic/claude-haiku-4.5\"; streamcallback=callback)\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.aigen_raw-Tuple{Any, String}","page":"Home","title":"OpenRouter.aigen_raw","text":"aigen_raw(prompt, provider_model::String; \n          schema::Union{AbstractRequestSchema, Nothing} = nothing,\n          api_key::Union{String, Nothing} = nothing,\n          sys_msg = nothing,\n          streamcallback::Union{Nothing, AbstractLLMStream} = nothing,\n          kwargs...)\n\nGenerate text using a specific provider and model, returning raw API response and parsing components.\n\nThis function is useful for:\n\nTesting equivalence between streaming and non-streaming responses\nDebugging API response formats\nCustom response processing\n\nReturns\n\nNamedTuple: Contains (result, schema, provider_info, model_id, provider_endpoint, elapsed)\n\nExample\n\n# Compare streaming vs non-streaming raw responses\nraw_stream = aigen_raw(\"Hello\", \"anthropic:claude-3-sonnet\"; streamcallback=HttpStreamCallback())\nraw_normal = aigen_raw(\"Hello\", \"anthropic:claude-3-sonnet\")\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.anthropic_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.anthropic_model_transform","text":"anthropic_model_transform(model_id::String)::String\n\nTransform model IDs for Anthropic. Removes anthropic/ prefix and replaces dots with dashes. Also handles special cases and version matching.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.build_headers-Tuple{OpenRouter.ProviderInfo, AbstractString}","page":"Home","title":"OpenRouter.build_headers","text":"Build complete headers for a provider request.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.build_messages-Tuple{OpenRouter.AnthropicSchema, Any, Any}","page":"Home","title":"OpenRouter.build_messages","text":"Build messages array for AnthropicSchema.\n\nReturns a tuple: (messages, system_content)\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.build_messages-Tuple{OpenRouter.ChatCompletionSchema, Any, Any}","page":"Home","title":"OpenRouter.build_messages","text":"Build messages array for ChatCompletionSchema.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.build_messages-Tuple{OpenRouter.GeminiSchema, Any, Any}","page":"Home","title":"OpenRouter.build_messages","text":"Build contents array for GeminiSchema.\n\nReturns a tuple: (contents, system_instruction)\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.build_native_models_url-Tuple{OpenRouter.ProviderInfo}","page":"Home","title":"OpenRouter.build_native_models_url","text":"build_native_models_url(provider_info::ProviderInfo)::String\n\nBuild the models endpoint URL for a provider's native API.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.build_payload","page":"Home","title":"OpenRouter.build_payload","text":"Build the request payload for ChatCompletionSchema.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.build_payload-2","page":"Home","title":"OpenRouter.build_payload","text":"Build the request payload for AnthropicSchema.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.build_payload-3","page":"Home","title":"OpenRouter.build_payload","text":"Build the request payload for GeminiSchema.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.build_response_body-Tuple{OpenRouter.AnthropicSchema, OpenRouter.AbstractLLMStream}","page":"Home","title":"OpenRouter.build_response_body","text":"build_response_body(schema::AnthropicSchema, cb::AbstractLLMStream; verbose::Bool = false, kwargs...)\n\nBuild response body from chunks to mimic standard Anthropic API response.\n\nNote: Limited functionality. Does NOT support tool use.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.build_response_body-Tuple{OpenRouter.ChatCompletionSchema, OpenRouter.AbstractLLMStream}","page":"Home","title":"OpenRouter.build_response_body","text":"build_response_body(schema::ChatCompletionSchema, cb::AbstractLLMStream; verbose::Bool = false, kwargs...)\n\nBuild response body from chunks to mimic standard ChatCompletion API response.\n\nNote: Limited functionality. Does NOT support tool use, refusals, logprobs.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.build_response_body-Tuple{OpenRouter.GeminiSchema, OpenRouter.AbstractLLMStream}","page":"Home","title":"OpenRouter.build_response_body","text":"build_response_body(schema::GeminiSchema, cb::AbstractLLMStream; verbose::Bool = false, kwargs...)\n\nBuild response body from chunks to mimic standard Gemini API response.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.build_response_body-Tuple{OpenRouter.ResponseSchema, OpenRouter.AbstractLLMStream}","page":"Home","title":"OpenRouter.build_response_body","text":"build_response_body(schema::ResponseSchema, cb::AbstractLLMStream; verbose::Bool = false, kwargs...)\n\nBuild response body from chunks.  Optimized to find the final response.completed object immediately (O(1) effectively), with a fallback reconstruction for interrupted streams.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.build_url","page":"Home","title":"OpenRouter.build_url","text":"Build the URL for AnthropicSchema.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.build_url-2","page":"Home","title":"OpenRouter.build_url","text":"Build the URL for GeminiSchema (handles model parameter substitution and streaming).\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.build_url-3","page":"Home","title":"OpenRouter.build_url","text":"Build the URL for ChatCompletionSchema.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.calculate_cost-Tuple{Pricing, Union{Nothing, OpenRouter.TokenCounts, Dict}}","page":"Home","title":"OpenRouter.calculate_cost","text":"Calculate cost based on pricing and token usage.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.calculate_cost-Tuple{ProviderEndpoint, Union{Nothing, Dict}}","page":"Home","title":"OpenRouter.calculate_cost","text":"Calculate cost for a given endpoint and token usage. Unwraps .pricing. Warns if cost cannot be determined (e.g. missing pricing).\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.calculate_cost-Tuple{ProviderEndpoint, Union{Nothing, OpenRouter.TokenCounts, Dict}}","page":"Home","title":"OpenRouter.calculate_cost","text":"Calculate cost for a given endpoint and token usage. Unwraps .pricing. Warns if cost cannot be determined (e.g. missing pricing).\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.callback-Tuple{HttpStreamCallback, OpenRouter.AbstractStreamChunk}","page":"Home","title":"OpenRouter.callback","text":"callback(cb::AbstractLLMStream, chunk::AbstractStreamChunk; kwargs...)\n\nProcess chunk and print it. Wrapper for:\n\nextract content from chunk using extract_content\nprint content to output stream using print_content\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.callback-Tuple{OpenRouter.AbstractLLMStream, OpenRouter.AbstractStreamChunk}","page":"Home","title":"OpenRouter.callback","text":"callback(cb::AbstractLLMStream, chunk::AbstractStreamChunk; kwargs...)\n\nProcess chunk and print it. Wrapper for:\n\nextract content from chunk using extract_content\nprint content to output stream using print_content\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.cerebras_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.cerebras_model_transform","text":"cerebras_model_transform(model_id::String)::String\n\nTransform model IDs for Cerebras.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.cohere_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.cohere_model_transform","text":"cohere_model_transform(model_id::String)::String\n\nTransform model IDs for Cohere. Currently returns unchanged.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.configure_stream_callback!-Tuple{OpenRouter.AbstractLLMStream, OpenRouter.AbstractRequestSchema, OpenRouter.ProviderInfo, ProviderEndpoint}","page":"Home","title":"OpenRouter.configure_stream_callback!","text":"configure_stream_callback!(cb::AbstractLLMStream, schema::AbstractRequestSchema, provider_info::ProviderInfo, provider_endpoint::ProviderEndpoint)\n\nConfigure stream callback with schema and provider information. For HttpStreamHooks, also sets up pricing for accurate cost calculation.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.deepseek_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.deepseek_model_transform","text":"deepseek_model_transform(model_id::String)::String\n\nTransform model IDs for DeepSeek. Currently returns unchanged.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_content-Tuple{OpenRouter.AnthropicSchema, Dict}","page":"Home","title":"OpenRouter.extract_content","text":"Extract response content for AnthropicSchema.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_content-Tuple{OpenRouter.AnthropicSchema, OpenRouter.AbstractStreamChunk}","page":"Home","title":"OpenRouter.extract_content","text":"extract_content(schema::AnthropicSchema, chunk::AbstractStreamChunk;\n    include_thinking::Bool = true, kwargs...)\n\nExtract content from Anthropic chunk.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_content-Tuple{OpenRouter.ChatCompletionSchema, Dict}","page":"Home","title":"OpenRouter.extract_content","text":"Extract response content for ChatCompletionSchema.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_content-Tuple{OpenRouter.ChatCompletionSchema, OpenRouter.AbstractStreamChunk}","page":"Home","title":"OpenRouter.extract_content","text":"extract_content(schema::ChatCompletionSchema, chunk::AbstractStreamChunk; kwargs...)\n\nExtract content from ChatCompletion chunk.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_content-Tuple{OpenRouter.GeminiSchema, Dict}","page":"Home","title":"OpenRouter.extract_content","text":"Extract response content for GeminiSchema.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_content-Tuple{OpenRouter.GeminiSchema, StreamChunk}","page":"Home","title":"OpenRouter.extract_content","text":"extract_content(schema::GeminiSchema, chunk::StreamChunk; kwargs...)\n\nExtract regular (non-reasoning) content from Gemini chunk.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_content-Tuple{OpenRouter.ResponseSchema, OpenRouter.AbstractStreamChunk}","page":"Home","title":"OpenRouter.extract_content","text":"extract_content(schema::ResponseSchema, chunk::AbstractStreamChunk; kwargs...)\n\nExtract content from Response API chunk.  Only extracts 'delta' to ensure stream consumers don't print duplicate content  (since 'done' events contain the full text).\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_finish_reason-Tuple{OpenRouter.ChatCompletionSchema, Dict}","page":"Home","title":"OpenRouter.extract_finish_reason","text":"Extract finish reason from API response based on schema.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_provider_from_model-Tuple{String}","page":"Home","title":"OpenRouter.extract_provider_from_model","text":"extract_provider_from_model(model_name::String) -> String\n\nExtract provider name from model name in format \"provider:author/model_id\" or fallback to \"openai\".\n\nExamples\n\nextract_provider_from_model(\"openai:openai/gpt-4\") # => \"openai\"\nextract_provider_from_model(\"anthropic:anthropic/claude-3-5-sonnet\") # => \"anthropic\"\nextract_provider_from_model(\"cerebras:meta-llama/llama-3.1-8b\") # => \"cerebras\"\nextract_provider_from_model(\"gpt-4\") # => \"openai\" (fallback)\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_reasoning-Tuple{OpenRouter.ChatCompletionSchema, Dict}","page":"Home","title":"OpenRouter.extract_reasoning","text":"Extract reasoning content from API response based on schema. Returns nothing if schema doesn't support reasoning or no reasoning found.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_reasoning_from_chunk-Tuple{OpenRouter.GeminiSchema, StreamChunk}","page":"Home","title":"OpenRouter.extract_reasoning_from_chunk","text":"extract_reasoning_from_chunk(schema::GeminiSchema, chunk::StreamChunk)\n\nExtract reasoning/thinking content from Gemini chunk (parts with \"thought\": true).\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_response-Tuple{OpenRouter.ChatCompletionResponseSchema, Dict}","page":"Home","title":"OpenRouter.extract_response","text":"Extract full response for ChatCompletionResponseSchema.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.extract_tokens-Tuple{OpenRouter.ChatCompletionSchema, Union{Dict, JSON3.Object}}","page":"Home","title":"OpenRouter.extract_tokens","text":"Extract token usage information from API response based on schema. Returns TokenCounts struct with standardized field names.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.fetch_native_models-Tuple{OpenRouter.ProviderInfo, String}","page":"Home","title":"OpenRouter.fetch_native_models","text":"fetch_native_models(provider_info::ProviderInfo, api_key::String)::Vector{Dict}\n\nFetch models directly from a provider's native API. Returns raw model data as returned by the provider.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.fireworks_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.fireworks_model_transform","text":"fireworks_model_transform(model_id::String)::String\n\nTransform model IDs for Fireworks. Currently returns unchanged.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.get_inference_elapsed-Tuple{OpenRouter.RunInfo}","page":"Home","title":"OpenRouter.get_inference_elapsed","text":"get_inference_elapsed(info::RunInfo)\n\nGet elapsed time for inference (time between first inference and last message). Returns time in seconds or nothing if inference hasn't started.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.get_provider_auth_header-Tuple{AbstractString, AbstractString}","page":"Home","title":"OpenRouter.get_provider_auth_header","text":"Build an auth header pair (name => value) for a provider + API key, or nothing if provider is unknown.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.get_provider_auth_header-Tuple{OpenRouter.ProviderInfo, AbstractString}","page":"Home","title":"OpenRouter.get_provider_auth_header","text":"Build an auth header pair (name => value) for a ProviderInfo + API key.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.get_provider_base_url-Tuple{AbstractString}","page":"Home","title":"OpenRouter.get_provider_base_url","text":"Get just the base URL for a provider slug, or nothing if unknown.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.get_provider_env_var_name-Tuple{AbstractString}","page":"Home","title":"OpenRouter.get_provider_env_var_name","text":"Return the configured API key env var name for a provider, or nothing.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.get_provider_info-Tuple{AbstractString}","page":"Home","title":"OpenRouter.get_provider_info","text":"Get the provider info for a given slug, or nothing if unknown.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.get_provider_schema-Tuple{OpenRouter.ProviderInfo, AbstractString}","page":"Home","title":"OpenRouter.get_provider_schema","text":"Get the appropriate schema for a provider info and model. For OpenAI, use ResponseSchema for gpt-5 and o-series models.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.get_total_elapsed-Tuple{OpenRouter.RunInfo}","page":"Home","title":"OpenRouter.get_total_elapsed","text":"get_total_elapsed(info::RunInfo)\n\nGet total elapsed time since callback creation. Returns time in seconds or nothing if no messages received.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.google_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.google_model_transform","text":"google_model_transform(model_id::String)::String\n\nTransform model IDs for Google. Removes google/ prefix.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.groq_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.groq_model_transform","text":"groq_model_transform(model_id::String)::String\n\nTransform OpenRouter model IDs to Groq-specific model IDs. Handles various model mappings for Groq's native API.\n\nExamples\n\ngroq_model_transform(\"moonshotai/kimi-k2-0905\")  # => \"moonshotai/kimi-k2-instruct-0905\"\ngroq_model_transform(\"other/model\")              # => \"other/model\"\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.handle_error_message-Tuple{OpenRouter.AbstractStreamChunk}","page":"Home","title":"OpenRouter.handle_error_message","text":"handle_error_message(chunk::AbstractStreamChunk; kwargs...)\n\nHandle error messages from streaming response. Always throws on error.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.is_done-Tuple{OpenRouter.ChatCompletionSchema, OpenRouter.AbstractStreamChunk}","page":"Home","title":"OpenRouter.is_done","text":"is_done(schema::ChatCompletionSchema, chunk::AbstractStreamChunk; kwargs...)\n\nCheck if streaming is done for ChatCompletion format.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.is_done-Tuple{OpenRouter.ResponseSchema, OpenRouter.AbstractStreamChunk}","page":"Home","title":"OpenRouter.is_done","text":"is_done(schema::ResponseSchema, chunk::AbstractStreamChunk; kwargs...)\n\nCheck if streaming is done for Response API format.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.is_known_provider-Tuple{AbstractString}","page":"Home","title":"OpenRouter.is_known_provider","text":"Check if this provider slug is known.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.list_aliases-Tuple{}","page":"Home","title":"OpenRouter.list_aliases","text":"list_aliases()::Dict{String, String}\n\nList all available model aliases.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.list_embeddings_models","page":"Home","title":"OpenRouter.list_embeddings_models","text":"list_embeddings_models(api_key::String = get(ENV, \"OPENROUTER_API_KEY\", \"\"))::Vector{OpenRouterEmbeddingModel}\n\nReturn parsed embedding models list as Julia structs. Uses OPENROUTERAPIKEY environment variable by default.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.list_embeddings_models_raw","page":"Home","title":"OpenRouter.list_embeddings_models_raw","text":"list_embeddings_models_raw(api_key::String = get(ENV, \"OPENROUTER_API_KEY\", \"\"))::String\n\nReturn raw JSON string of embedding models list. Uses OPENROUTERAPIKEY environment variable by default.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.list_endpoints","page":"Home","title":"OpenRouter.list_endpoints","text":"list_endpoints(model_id::String, api_key::String = get(ENV, \"OPENROUTER_API_KEY\", \"\"))::ModelProviders\n\nReturn parsed endpoints for a specific model from OpenRouter as Julia struct. Model ID should be in format \"author/slug\" (e.g., \"moonshotai/kimi-k2-thinking\"). Uses OPENROUTERAPIKEY environment variable by default.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.list_endpoints_raw","page":"Home","title":"OpenRouter.list_endpoints_raw","text":"list_endpoints_raw(model_id::String, api_key::String = get(ENV, \"OPENROUTER_API_KEY\", \"\"))::String\n\nReturn raw JSON string of endpoints for a specific model from OpenRouter. Model ID should be in format \"author/slug\" (e.g., \"moonshotai/kimi-k2-thinking\"). Uses OPENROUTERAPIKEY environment variable by default.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.list_known_providers-Tuple{}","page":"Home","title":"OpenRouter.list_known_providers","text":"List all known provider slugs.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.list_models","page":"Home","title":"OpenRouter.list_models","text":"list_models(provider_filter::Union{String, Nothing} = nothing, api_key::String = get(ENV, \"OPENROUTER_API_KEY\", \"\"))::Vector{OpenRouterModel}\n\nReturn parsed model list as Julia structs, optionally filtered by provider. Uses OPENROUTERAPIKEY environment variable by default.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.list_models_raw","page":"Home","title":"OpenRouter.list_models_raw","text":"list_models_raw(api_key::String = get(ENV, \"OPENROUTER_API_KEY\", \"\"))::String\n\nReturn raw JSON string of model list. Uses OPENROUTERAPIKEY environment variable by default.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.list_native_models","page":"Home","title":"OpenRouter.list_native_models","text":"list_native_models(provider_slug::String, api_key::String = \"\")::Vector{Dict}\n\nList models using a provider's native API. Returns raw model data as returned by the provider.\n\nExample\n\nmodels = list_native_models(\"cerebras\")\nmodels = list_native_models(\"openai\", \"your-api-key\")\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.list_provider_endpoints","page":"Home","title":"OpenRouter.list_provider_endpoints","text":"list_provider_endpoints(provider_filter::String, api_key::String = get(ENV, \"OPENROUTER_API_KEY\", \"\"))::Vector{ProviderEndpoint}\n\nReturn all ProviderEndpoint entries hosted by the given provider.\n\nThis uses the cached model database with endpoints; it will fetch endpoints as needed on first call.\n\nExample:\n\ngroq_eps = list_provider_endpoints(\"groq\")\nfor ep in groq_eps\n    println(ep.provider_name, \" \", ep.name, \" (\", ep.model_name, \")\")\nend\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.list_providers","page":"Home","title":"OpenRouter.list_providers","text":"list_providers(model_id::String, api_key::String = get(ENV, \"OPENROUTER_API_KEY\", \"\"))::ModelProviders\n\nReturn parsed providers for a specific model as Julia struct. Model ID should be in format \"author/slug\" (e.g., \"moonshotai/kimi-k2-thinking\"). Uses OPENROUTERAPIKEY environment variable by default.\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.list_providers-Tuple{}","page":"Home","title":"OpenRouter.list_providers","text":"list_providers()\n\nList all registered providers.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.list_providers_raw","page":"Home","title":"OpenRouter.list_providers_raw","text":"list_providers_raw(model_id::String, api_key::String = get(ENV, \"OPENROUTER_API_KEY\", \"\"))::String\n\nReturn raw JSON string of providers for a specific model. ...\n\n\n\n\n\n","category":"function"},{"location":"#OpenRouter.minimax_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.minimax_model_transform","text":"minimax_model_transform(model_id::String)::String\n\nTransform model IDs for Minimax. Currently returns unchanged.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.mistral_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.mistral_model_transform","text":"mistral_model_transform(model_id::String)::String\n\nTransform model IDs for Mistral. Currently returns unchanged.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.moonshotai_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.moonshotai_model_transform","text":"moonshotai_model_transform(model_id::String)::String\n\nTransform model IDs for MoonshotAI. Currently returns unchanged.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.needs_tool_execution-Tuple{OpenRouter.RunInfo}","page":"Home","title":"OpenRouter.needs_tool_execution","text":"needs_tool_execution(info::RunInfo)\n\nCheck if the run was terminated because the model is requested tool execution (with stop_sequence).\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.normalize_messages-Tuple{Any, Any}","page":"Home","title":"OpenRouter.normalize_messages","text":"Normalize prompt + sys_msg into a flat vector of AbstractMessage.\n\nAccepted prompt forms:\n\nString                => one UserMessage\nAbstractMessage       => wrapped in a vector\nVector of items       => each element may be\nAbstractMessage\nString            => treated as UserMessage\nanything else     => treated as UserMessage with that content\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.openai_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.openai_model_transform","text":"openai_model_transform(model_id::String)::String\n\nTransform model IDs for OpenAI. Removes openai/ prefix and handles specific mappings.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.parse_embedding_models-Tuple{String}","page":"Home","title":"OpenRouter.parse_embedding_models","text":"parse_embedding_models(json_str::String)::Vector{OpenRouterEmbeddingModel}\n\nParse OpenRouter embedding models JSON response into Julia structs.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.parse_endpoints-Tuple{String}","page":"Home","title":"OpenRouter.parse_endpoints","text":"parse_endpoints(json_str::String)::ModelProviders\n\nParse model providers JSON response into Julia struct.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.parse_models-Tuple{String}","page":"Home","title":"OpenRouter.parse_models","text":"parse_models(json_str::String)::Vector{OpenRouterModel}\n\nParse OpenRouter models JSON response into Julia structs.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.print_content-Tuple{Channel, AbstractString}","page":"Home","title":"OpenRouter.print_content","text":"print_content(out::Channel, text::AbstractString; kwargs...)\n\nPrint content to Channel.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.print_content-Tuple{IO, AbstractString}","page":"Home","title":"OpenRouter.print_content","text":"print_content(out::IO, text::AbstractString; kwargs...)\n\nPrint content to IO output stream.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.print_content-Tuple{Nothing, Any}","page":"Home","title":"OpenRouter.print_content","text":"print_content(out::Nothing, text::Any; kwargs...)\n\nDo nothing if output stream is nothing.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.remove_custom_model-Tuple{String}","page":"Home","title":"OpenRouter.remove_custom_model","text":"remove_custom_model(id::String)\n\nRemove a custom model from the local cache.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.remove_model-Tuple{String}","page":"Home","title":"OpenRouter.remove_model","text":"remove_model(id::String)\n\nRemove a model from the local cache.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.remove_provider-Tuple{String}","page":"Home","title":"OpenRouter.remove_provider","text":"remove_provider(name::String)\n\nRemove a provider from the registry.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.resolve_model_alias-Tuple{AbstractString}","page":"Home","title":"OpenRouter.resolve_model_alias","text":"resolve_model_alias(model_id::String)::String\n\nResolve a model alias to the full provider:model format. If the input is not an alias, returns it unchanged.\n\nExample\n\nresolve_model_alias(\"gemf\")  # Returns \"google-ai-studio:google/gemini-2.5-flash-preview-09-2025\"\nresolve_model_alias(\"anthropic:claude-3-sonnet\")  # Returns unchanged\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.sambanova_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.sambanova_model_transform","text":"sambanova_model_transform(model_id::String)::String\n\nTransform model IDs for SambaNova. Currently returns unchanged.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.streamed_request!-Tuple{OpenRouter.AbstractLLMStream, Any, Any, IOBuffer}","page":"Home","title":"OpenRouter.streamed_request!","text":"streamed_request!(cb::AbstractLLMStream, url, headers, input; kwargs...)\n\nEnd-to-end wrapper for POST streaming requests. Modifies callback object (cb.chunks) in-place and returns response object.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.strip_provider_prefix-Tuple{AbstractString, AbstractString}","page":"Home","title":"OpenRouter.strip_provider_prefix","text":"strip_provider_prefix(model_id::AbstractString, provider::AbstractString)::AbstractString\n\nRemove provider prefix from model ID if present. Helper function for model transformations.\n\nExamples\n\nstrip_provider_prefix(\"openai/gpt-4\", \"openai\")     # => \"gpt-4\"\nstrip_provider_prefix(\"gpt-4\", \"openai\")            # => \"gpt-4\"\nstrip_provider_prefix(\"google/gemini-pro\", \"google\") # => \"gemini-pro\"\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.together_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.together_model_transform","text":"together_model_transform(model_id::String)::String\n\nTransform model IDs for Together. Currently returns unchanged.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.transform_model_name-Tuple{OpenRouter.ProviderInfo, AbstractString}","page":"Home","title":"OpenRouter.transform_model_name","text":"Transform model name according to provider-specific rules.\n\n\n\n\n\n","category":"method"},{"location":"#OpenRouter.xai_model_transform-Tuple{AbstractString}","page":"Home","title":"OpenRouter.xai_model_transform","text":"xai_model_transform(model_id::String)::String\n\nTransform model IDs for xAI. Removes x-ai/ prefix and handles specific mappings.\n\n\n\n\n\n","category":"method"}]
}
